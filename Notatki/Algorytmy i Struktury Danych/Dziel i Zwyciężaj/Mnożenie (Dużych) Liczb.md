**Dane:**
Liczby: $a = a_{n-1},a_{n-2},\dots,a_{1},a_{0}$ oraz $b = b_{n-1},b_{n-2},\dots,b_{1},b_{0}$

**Zadanie:**
Policzyć $a\cdot b$.

> Mnożenie jako `imul` odpada, bo przecież nie przecież nie potrafimy robić takich rzeczy.

## Naiwnie

Mnożymy każdy bit z każdym i liczymy sumę.
To zajmuje czas kwadratowy $O(n^{2})$.

## Dziel i Zwyciężaj

> Istnieją lepsze algorytmy niż ten o złożoności $O(n \log(n)\cdot \log\log(n))$

Przyjmijmy, że mamy zadanie pomnożyć dwie liczby $a,b$ obie o długości $n$.

Metoda Karatsuby zakłada podzielenie liczb na połowy:

- $a = a_{0} + a_{1}\cdot 2^{s}$
- $b = b_{0} + b_{1}\cdot 2^{s}$

By następnie policzyć wyrażenie:
$$\begin{align*}
ab &= 2^{2s} c_{2} + 2^{s}c_{1} + c_{0}\\
c_{0} &= a_{0}b_{0}\\
c_{1} &= a_{1}b_{0} + a_{0}b_{1}\\
c_{2} &= a_{1}b_{1}
\end{align*}$$
Teraz by algorytm działał szybciej niż naiwny algorytm kwadratowy chcemy wykonać mniej niż $4$ mnożenia, by uzyskać wartości $c_{0},c_{1},c_{2}$.
Policzymy więc na początku $c_{0}$ i $c_{2}$ na co potrzebujemy dwóch mnożeń.
Później policzymy $c_{1} = (a_{1} + a_{0})(b_{1} + b_{0}) - c_{0} - c_{2}$.
Wszystkie trzy mnożenia dotyczą liczb mniej-więcej $\frac{n}{2}$ bitowych (uznajemy, że dodawanie i odejmowanie jest tanie). Otrzymujemy więc koszt będący rekurencją:
$$\begin{align*}
T(n) &= 3T\left(\frac{n}{2}\right) + \Theta(n) = \Theta(n^{\log_{2}3})
\end{align*}$$

### Ogólna Wersja Algorytmu

> Od tego miejsca notatka się psuje trochę bo nie widzę sensu tego co tu robimy.

Podzielmy obie liczby $a,b$ na $k$ kawałków $\frac{n}{k}$ bitowych:

- $a = \sum\limits_{i=0}^{k-1}2^{\frac{in}{k}}a_{i}$
- $b = \sum\limits_{i=0}^{k-1}2^{\frac{in}{k}}b_{i}$

Teraz potrzebujemy policzyć wartość $\sum\limits_{i=0}^{2k-2}2^{\frac{in}{k}}c_{i}$, gdzie kolejne  $c_{i}$ dla $i\in\{0,\dots,2k-2\}$:
$$c_{i} = \sum\limits_{r=0}^{i}a_{r}\cdot b_{i-r}$$
Dalej *wyczarowujemy* sobie ciąg liczb $w_{1},\dots,w_{2k-1}$:
$$
w_{t} = \left( \sum\limits_{i=0}^{k-1}a_{i}t^{i} \right) \cdot \left( \sum\limits_{i=0}^{k-1} b_{i}t^{i} \right)
$$
Definiujemy je w taki sposób, by spełniały zależność $w_{t} = \sum\limits_{j=0}^{2k-2}c_{j}t^{j}$ co jednocześnie definiuje nam układ równań, który możemy zapisać następująco:
$$
U \cdot [c_{0},c_{1},\dots,c_{2k-2}]^{T} = [w_{1},w_{2},\dots,w_{2k-1}]^{T}
$$
Gdzie macierz $U = \{u_{ij}\}, u_{ij} = i^{j}$  jest odwracalna, więc układ jest rozwiązywalny.

Teraz zauważamy, że ciąg $w_{i}$ składa się z mniejszych elementów, które możemy policzyć rekurencyjnie.

Algorytm ten będzie działał w czasie $\Theta(n^{\log_{k}(2k-1)})$, bo wykonujemy $(2k-1)$ rekurencyjnych wywołań dla danych rozmiaru $\frac{n}{k}$ (to jest oczywiście nieformalne).